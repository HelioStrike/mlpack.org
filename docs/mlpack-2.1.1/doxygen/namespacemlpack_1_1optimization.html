<html >
<head >

<meta name="keywords" content="mlpack, libmlpack, c++, armadillo, machine
learning, data mining, classification, regression, tree-based methods, dual-tree
algorithm">
<meta name="description" content="mlpack: a scalable c++ machine learning
library">
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title >mlpack: a scalable c++ machine learning library</title>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript" src="dynamic_tables.js"></script>
</head><link rel="stylesheet" href="style-doxygen.css" /><link rel="stylesheet" href="doxygen.css" /><link rel="stylesheet" href="tabs.css" /><link rel="stylesheet" href="search/search.css" /><link href="http://fonts.googleapis.com/css?family=Maven+Pro:500" rel="stylesheet" type="text/css" />





<body ><br />


<div class="mlpack_titlebar">
   <a href="http://www.mlpack.org"><img src="../../../mlpack.png"></a>
</div>
<center >
<div class="mlnavbar">
  <div class="navcontainer">
   <div class="mlnavitem" name="mlnavmain"><a href="../../../index.html">main</a></div>
   <div class="mlnavitem" name="mlnavabout"><a href="../../../about.html">about</a></div>
   <div class="mlnavitem" name="mlnavdoc"><a href="../../../docs.html">docs</a></div>
   <div class="mlnavitem" name="mlnavhelp"><a href="../../../help.html">get help</a></div>
   <div class="mlnavitem" name="mlnavbugs"><a href="https://github.com/mlpack/mlpack">github</a></div>
  </div>
</div>
</center>
<div class="separator"></div>
<center >
<div class="mainsection smallertext">
<div id="top">
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody >
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">mlpack
   &#160;<span id="projectnumber">2.1.1</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>

<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',false,false,'search.php','Search');
});
</script>
<div id="main-nav"></div>
<div id="nav-path" class="navpath">
  <ul >
<li class="navelem"><a class="el" href="namespacemlpack.html">mlpack</a></li><li class="navelem"><a class="el" href="namespacemlpack_1_1optimization.html">optimization</a></li>  </ul>
</div>
</div>
<div class="header">
  <div class="summary">
<a href="#namespaces">Namespaces</a> &#124;
<a href="#nested-classes">Classes</a>  </div>
  <div class="headertitle">
<div class="title">mlpack::optimization Namespace Reference</div>  </div>
</div>
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="namespaces"></a>
Namespaces</h2></td></tr>
<tr class="memitem:namespacemlpack_1_1optimization_1_1test"><td class="memItemLeft" align="right" valign="top"> &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacemlpack_1_1optimization_1_1test.html">test</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1optimization_1_1AdaDelta.html">AdaDelta</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Adadelta is an optimizer that uses two ideas to improve upon the two main drawbacks of the Adagrad method:  <a href="classmlpack_1_1optimization_1_1AdaDelta.html#details">More...</a><br /></br></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1optimization_1_1Adam.html">Adam</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="classmlpack_1_1optimization_1_1Adam.html" title="Adam is an optimizer that computes individual adaptive learning rates for different parameters from e...">Adam</a> is an optimizer that computes individual adaptive learning rates for different parameters from estimates of first and second moments of the gradients.  <a href="classmlpack_1_1optimization_1_1Adam.html#details">More...</a><br /></br></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1optimization_1_1AugLagrangian.html">AugLagrangian</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">The <a class="el" href="classmlpack_1_1optimization_1_1AugLagrangian.html" title="The AugLagrangian class implements the Augmented Lagrangian method of optimization. ">AugLagrangian</a> class implements the Augmented Lagrangian method of optimization.  <a href="classmlpack_1_1optimization_1_1AugLagrangian.html#details">More...</a><br /></br></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1optimization_1_1AugLagrangianFunction.html">AugLagrangianFunction</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">This is a utility class used by <a class="el" href="classmlpack_1_1optimization_1_1AugLagrangian.html" title="The AugLagrangian class implements the Augmented Lagrangian method of optimization. ">AugLagrangian</a>, meant to wrap a LagrangianFunction into a function usable by a simple optimizer like L-BFGS.  <a href="classmlpack_1_1optimization_1_1AugLagrangianFunction.html#details">More...</a><br /></br></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1optimization_1_1AugLagrangianTestFunction.html">AugLagrangianTestFunction</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function is taken from "Practical Mathematical Optimization" (Snyman), section 5.3.8 ("Application of the Augmented Lagrangian Method").  <a href="classmlpack_1_1optimization_1_1AugLagrangianTestFunction.html#details">More...</a><br /></br></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1optimization_1_1ExponentialSchedule.html">ExponentialSchedule</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">The exponential cooling schedule cools the temperature T at every step according to the equation.  <a href="classmlpack_1_1optimization_1_1ExponentialSchedule.html#details">More...</a><br /></br></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1optimization_1_1GockenbachFunction.html">GockenbachFunction</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function is taken from M.  <a href="classmlpack_1_1optimization_1_1GockenbachFunction.html#details">More...</a><br /></br></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1optimization_1_1GradientDescent.html">GradientDescent</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gradient Descent is a technique to minimize a function.  <a href="classmlpack_1_1optimization_1_1GradientDescent.html#details">More...</a><br /></br></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1optimization_1_1L__BFGS.html">L_BFGS</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">The generic L-BFGS optimizer, which uses a back-tracking line search algorithm to minimize a function.  <a href="classmlpack_1_1optimization_1_1L__BFGS.html#details">More...</a><br /></br></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1optimization_1_1LovaszThetaSDP.html">LovaszThetaSDP</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function is the Lovasz-Theta semidefinite program, as implemented in the following paper:  <a href="classmlpack_1_1optimization_1_1LovaszThetaSDP.html#details">More...</a><br /></br></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1optimization_1_1LRSDP.html">LRSDP</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="classmlpack_1_1optimization_1_1LRSDP.html" title="LRSDP is the implementation of Monteiro and Burer's formulation of low-rank semidefinite programs (LR...">LRSDP</a> is the implementation of Monteiro and Burer's formulation of low-rank semidefinite programs (LR-SDP).  <a href="classmlpack_1_1optimization_1_1LRSDP.html#details">More...</a><br /></br></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1optimization_1_1LRSDPFunction.html">LRSDPFunction</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">The objective function that <a class="el" href="classmlpack_1_1optimization_1_1LRSDP.html" title="LRSDP is the implementation of Monteiro and Burer's formulation of low-rank semidefinite programs (LR...">LRSDP</a> is trying to optimize.  <a href="classmlpack_1_1optimization_1_1LRSDPFunction.html#details">More...</a><br /></br></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1optimization_1_1MiniBatchSGD.html">MiniBatchSGD</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Mini-batch Stochastic Gradient Descent is a technique for minimizing a function which can be expressed as a sum of other functions.  <a href="classmlpack_1_1optimization_1_1MiniBatchSGD.html#details">More...</a><br /></br></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1optimization_1_1PrimalDualSolver.html">PrimalDualSolver</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Interface to a primal dual interior point solver.  <a href="classmlpack_1_1optimization_1_1PrimalDualSolver.html#details">More...</a><br /></br></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1optimization_1_1RMSprop.html">RMSprop</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="classmlpack_1_1optimization_1_1RMSprop.html" title="RMSprop is an optimizer that utilizes the magnitude of recent gradients to normalize the gradients...">RMSprop</a> is an optimizer that utilizes the magnitude of recent gradients to normalize the gradients.  <a href="classmlpack_1_1optimization_1_1RMSprop.html#details">More...</a><br /></br></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1optimization_1_1SA.html">SA</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Simulated Annealing is an stochastic optimization algorithm which is able to deliver near-optimal results quickly without knowing the gradient of the function being optimized.  <a href="classmlpack_1_1optimization_1_1SA.html#details">More...</a><br /></br></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1optimization_1_1SDP.html">SDP</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Specify an <a class="el" href="classmlpack_1_1optimization_1_1SDP.html" title="Specify an SDP in primal form. ">SDP</a> in primal form.  <a href="classmlpack_1_1optimization_1_1SDP.html#details">More...</a><br /></br></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1optimization_1_1SGD.html">SGD</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Stochastic Gradient Descent is a technique for minimizing a function which can be expressed as a sum of other functions.  <a href="classmlpack_1_1optimization_1_1SGD.html#details">More...</a><br /></br></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
</div>

<hr class="footer"></hr><address class="footer"><small >
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"></img>
</a> 1.8.13
</small></address>
</div>
</body>
<script type="text/javascript">
var x = document.querySelectorAll("img.formulaDsp");
var i;
for (i = 0; i < x.length; i++)
{
  x[i].width = x[i].offsetWidth / 4;
}
</script>
</html>