<html >
<head >

<meta name="keywords" content="mlpack, libmlpack, c++, armadillo, machine
learning, data mining, classification, regression, tree-based methods, dual-tree
algorithm">
<meta name="description" content="mlpack: a scalable c++ machine learning
library">
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title >mlpack: a scalable c++ machine learning library</title>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript" src="dynamic_tables.js"></script>
</head><link rel="stylesheet" href="style-doxygen.css" /><link rel="stylesheet" href="doxygen.css" /><link rel="stylesheet" href="tabs.css" /><link rel="stylesheet" href="search/search.css" /><link href="http://fonts.googleapis.com/css?family=Maven+Pro:500" rel="stylesheet" type="text/css" />





<body ><br />


<div class="mlpack_titlebar">
   <a href="http://www.mlpack.org"><img src="../../../mlpack.png"></a>
</div>
<center >
<div class="mlnavbar">
  <div class="navcontainer">
   <div class="mlnavitem" name="mlnavmain"><a href="../../../index.html">main</a></div>
   <div class="mlnavitem" name="mlnavabout"><a href="../../../about.html">about</a></div>
   <div class="mlnavitem" name="mlnavdoc"><a href="../../../docs.html">docs</a></div>
   <div class="mlnavitem" name="mlnavhelp"><a href="../../../help.html">get help</a></div>
   <div class="mlnavitem" name="mlnavbugs"><a href="https://github.com/mlpack/mlpack">github</a></div>
  </div>
</div>
</center>
<div class="separator"></div>
<center >
<div class="mainsection smallertext">
<div id="top">
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody >
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">mlpack
   &#160;<span id="projectnumber">3.0.1</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>

<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>

<div id="MSearchSelectWindow" onmouseover="return searchBox.OnSearchSelectShow()" onmouseout="return searchBox.OnSearchSelectHide()" onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>


<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul >
<li class="navelem"><a class="el" href="namespacemlpack.html">mlpack</a></li><li class="navelem"><a class="el" href="namespacemlpack_1_1optimization.html">optimization</a></li><li class="navelem"><a class="el" href="classmlpack_1_1optimization_1_1AdaGrad.html">AdaGrad</a></li>  </ul>
</div>
</div>
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="classmlpack_1_1optimization_1_1AdaGrad-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">AdaGrad Class Reference</div>  </div>
</div>
<div class="contents">

<p ><a class="el" href="classmlpack_1_1optimization_1_1AdaGrad.html" title="AdaGrad is a modified version of stochastic gradient descent which performs larger updates for more s...">AdaGrad</a> is a modified version of stochastic gradient descent which performs larger updates for more sparse parameters and smaller updates for less sparse parameters.  
 <a href="classmlpack_1_1optimization_1_1AdaGrad.html#details">More...</a></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:af11aae8f103202df8e06d6a7b44f3c42"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1optimization_1_1AdaGrad.html#af11aae8f103202df8e06d6a7b44f3c42">AdaGrad</a> (const double stepSize=0.01, const size_t batchSize=32, const double epsilon=1e-8, const size_t maxIterations=100000, const double tolerance=1e-5, const bool shuffle=true)</td></tr>
<tr class="memdesc:af11aae8f103202df8e06d6a7b44f3c42"><td class="mdescLeft">&#160;</td><td class="mdescRight">Construct the <a class="el" href="classmlpack_1_1optimization_1_1AdaGrad.html" title="AdaGrad is a modified version of stochastic gradient descent which performs larger updates for more s...">AdaGrad</a> optimizer with the given function and parameters.  <a href="#af11aae8f103202df8e06d6a7b44f3c42">More...</a><br /></br></td></tr>
<tr class="separator:af11aae8f103202df8e06d6a7b44f3c42"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7fc05cec06f55eb3c79d7f3f2fc197c5"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1optimization_1_1AdaGrad.html#a7fc05cec06f55eb3c79d7f3f2fc197c5">BatchSize</a> () const</td></tr>
<tr class="memdesc:a7fc05cec06f55eb3c79d7f3f2fc197c5"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the batch size.  <a href="#a7fc05cec06f55eb3c79d7f3f2fc197c5">More...</a><br /></br></td></tr>
<tr class="separator:a7fc05cec06f55eb3c79d7f3f2fc197c5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abe6fa63561dedf6d88b7076d174e818f"><td class="memItemLeft" align="right" valign="top">size_t &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1optimization_1_1AdaGrad.html#abe6fa63561dedf6d88b7076d174e818f">BatchSize</a> ()</td></tr>
<tr class="memdesc:abe6fa63561dedf6d88b7076d174e818f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Modify the batch size.  <a href="#abe6fa63561dedf6d88b7076d174e818f">More...</a><br /></br></td></tr>
<tr class="separator:abe6fa63561dedf6d88b7076d174e818f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af6d960193bb5db37e51416e12bf720de"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1optimization_1_1AdaGrad.html#af6d960193bb5db37e51416e12bf720de">Epsilon</a> () const</td></tr>
<tr class="memdesc:af6d960193bb5db37e51416e12bf720de"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the value used to initialise the squared gradient parameter.  <a href="#af6d960193bb5db37e51416e12bf720de">More...</a><br /></br></td></tr>
<tr class="separator:af6d960193bb5db37e51416e12bf720de"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab6a080993b32456443eced5df2f8b9b9"><td class="memItemLeft" align="right" valign="top">double &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1optimization_1_1AdaGrad.html#ab6a080993b32456443eced5df2f8b9b9">Epsilon</a> ()</td></tr>
<tr class="memdesc:ab6a080993b32456443eced5df2f8b9b9"><td class="mdescLeft">&#160;</td><td class="mdescRight">Modify the value used to initialise the squared gradient parameter.  <a href="#ab6a080993b32456443eced5df2f8b9b9">More...</a><br /></br></td></tr>
<tr class="separator:ab6a080993b32456443eced5df2f8b9b9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a420770944a5b0c7a852c4ec372c4a2d1"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1optimization_1_1AdaGrad.html#a420770944a5b0c7a852c4ec372c4a2d1">MaxIterations</a> () const</td></tr>
<tr class="memdesc:a420770944a5b0c7a852c4ec372c4a2d1"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the maximum number of iterations (0 indicates no limit).  <a href="#a420770944a5b0c7a852c4ec372c4a2d1">More...</a><br /></br></td></tr>
<tr class="separator:a420770944a5b0c7a852c4ec372c4a2d1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acda675ab4ab86b95c92bc33bc391a61b"><td class="memItemLeft" align="right" valign="top">size_t &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1optimization_1_1AdaGrad.html#acda675ab4ab86b95c92bc33bc391a61b">MaxIterations</a> ()</td></tr>
<tr class="memdesc:acda675ab4ab86b95c92bc33bc391a61b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Modify the maximum number of iterations (0 indicates no limit).  <a href="#acda675ab4ab86b95c92bc33bc391a61b">More...</a><br /></br></td></tr>
<tr class="separator:acda675ab4ab86b95c92bc33bc391a61b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a99a6cd3d7b60bad439f79f99ec0118a7"><td class="memTemplParams" colspan="2"><div class="template_expr"><div class="template_decl">template</div><div class="open_bracket">&lt;</div><div class="template_param_list"><div class="template_param"><div class="type_decl">typename</div><div class="identifier">DecomposableFunctionType</div><div class="close_bracket">&gt;</div></div></div></div></td></tr>
<tr class="memitem:a99a6cd3d7b60bad439f79f99ec0118a7"><td class="memTemplItemLeft" align="right" valign="top">double&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classmlpack_1_1optimization_1_1AdaGrad.html#a99a6cd3d7b60bad439f79f99ec0118a7">Optimize</a> (DecomposableFunctionType &amp;function, arma::mat &amp;iterate)</td></tr>
<tr class="memdesc:a99a6cd3d7b60bad439f79f99ec0118a7"><td class="mdescLeft">&#160;</td><td class="mdescRight">Optimize the given function using <a class="el" href="classmlpack_1_1optimization_1_1AdaGrad.html" title="AdaGrad is a modified version of stochastic gradient descent which performs larger updates for more s...">AdaGrad</a>.  <a href="#a99a6cd3d7b60bad439f79f99ec0118a7">More...</a><br /></br></td></tr>
<tr class="separator:a99a6cd3d7b60bad439f79f99ec0118a7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3905e5cdf39697b4f82a1a53a087ef37"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1optimization_1_1AdaGrad.html#a3905e5cdf39697b4f82a1a53a087ef37">Shuffle</a> () const</td></tr>
<tr class="memdesc:a3905e5cdf39697b4f82a1a53a087ef37"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get whether or not the individual functions are shuffled.  <a href="#a3905e5cdf39697b4f82a1a53a087ef37">More...</a><br /></br></td></tr>
<tr class="separator:a3905e5cdf39697b4f82a1a53a087ef37"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af374b2359713783f431ab1238dc524f3"><td class="memItemLeft" align="right" valign="top">bool &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1optimization_1_1AdaGrad.html#af374b2359713783f431ab1238dc524f3">Shuffle</a> ()</td></tr>
<tr class="memdesc:af374b2359713783f431ab1238dc524f3"><td class="mdescLeft">&#160;</td><td class="mdescRight">Modify whether or not the individual functions are shuffled.  <a href="#af374b2359713783f431ab1238dc524f3">More...</a><br /></br></td></tr>
<tr class="separator:af374b2359713783f431ab1238dc524f3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a11e6eb66d82a14ebd2943b49db676444"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1optimization_1_1AdaGrad.html#a11e6eb66d82a14ebd2943b49db676444">StepSize</a> () const</td></tr>
<tr class="memdesc:a11e6eb66d82a14ebd2943b49db676444"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the step size.  <a href="#a11e6eb66d82a14ebd2943b49db676444">More...</a><br /></br></td></tr>
<tr class="separator:a11e6eb66d82a14ebd2943b49db676444"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af6b273aba48a984b2847aa1593e09477"><td class="memItemLeft" align="right" valign="top">double &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1optimization_1_1AdaGrad.html#af6b273aba48a984b2847aa1593e09477">StepSize</a> ()</td></tr>
<tr class="memdesc:af6b273aba48a984b2847aa1593e09477"><td class="mdescLeft">&#160;</td><td class="mdescRight">Modify the step size.  <a href="#af6b273aba48a984b2847aa1593e09477">More...</a><br /></br></td></tr>
<tr class="separator:af6b273aba48a984b2847aa1593e09477"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7b5af5c1a84c507cbaa7f999ea5a4fda"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1optimization_1_1AdaGrad.html#a7b5af5c1a84c507cbaa7f999ea5a4fda">Tolerance</a> () const</td></tr>
<tr class="memdesc:a7b5af5c1a84c507cbaa7f999ea5a4fda"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the tolerance for termination.  <a href="#a7b5af5c1a84c507cbaa7f999ea5a4fda">More...</a><br /></br></td></tr>
<tr class="separator:a7b5af5c1a84c507cbaa7f999ea5a4fda"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3d9fac84af16250f5a3689692e8f2173"><td class="memItemLeft" align="right" valign="top">double &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1optimization_1_1AdaGrad.html#a3d9fac84af16250f5a3689692e8f2173">Tolerance</a> ()</td></tr>
<tr class="memdesc:a3d9fac84af16250f5a3689692e8f2173"><td class="mdescLeft">&#160;</td><td class="mdescRight">Modify the tolerance for termination.  <a href="#a3d9fac84af16250f5a3689692e8f2173">More...</a><br /></br></td></tr>
<tr class="separator:a3d9fac84af16250f5a3689692e8f2173"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p ><a class="el" href="classmlpack_1_1optimization_1_1AdaGrad.html" title="AdaGrad is a modified version of stochastic gradient descent which performs larger updates for more s...">AdaGrad</a> is a modified version of stochastic gradient descent which performs larger updates for more sparse parameters and smaller updates for less sparse parameters. </p>
<p >For more information, see the following.</p>
<div class="fragment"><div class="line">@article{duchi2011adaptive,</div><div class="line">  author  = {Duchi, John and Hazan, Elad and Singer, Yoram},</div><div class="line">  title   = {Adaptive subgradient methods <span class="keywordflow">for</span> online learning and stochastic</div><div class="line">             optimization},</div><div class="line">  journal = {Journal of Machine Learning Research},</div><div class="line">  volume  = {12},</div><div class="line">  number  = {Jul},</div><div class="line">  pages   = {2121--2159},</div><div class="line">  year    = {2011}</div><div class="line">}</div></div><p >For <a class="el" href="classmlpack_1_1optimization_1_1AdaGrad.html" title="AdaGrad is a modified version of stochastic gradient descent which performs larger updates for more s...">AdaGrad</a> to work, a DecomposableFunctionTypes template parameter is required. This class must implement the following function:</p>
<p >size_t NumFunctions(); double Evaluate(const arma::mat&amp; coordinates, const size_t i, const size_t batchSize); void Gradient(const arma::mat&amp; coordinates, const size_t i, arma::mat&amp; gradient, const size_t batchSize);</p>
<p >NumFunctions() should return the number of functions ( <img class="formulaInl" alt="$n$" src="form_48.png"></img>), and in the other two functions, the parameter i refers to which individual function (or gradient) is being evaluated. So, for the case of a data-dependent function, such as NCA (see <a class="el" href="classmlpack_1_1nca_1_1NCA.html" title="An implementation of Neighborhood Components Analysis, both a linear dimensionality reduction techniq...">mlpack::nca::NCA</a>), NumFunctions() should return the number of points in the dataset, and Evaluate(coordinates, 0) will evaluate the objective function on the first point in the dataset (presumably, the dataset is held internally in the DecomposableFunctionType). </p>

<p class="definition">Definition at line <a class="el" href="ada__grad_8hpp_source.html#l00064">64</a> of file <a class="el" href="ada__grad_8hpp_source.html">ada_grad.hpp</a>.</p>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="af11aae8f103202df8e06d6a7b44f3c42"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af11aae8f103202df8e06d6a7b44f3c42">&#9670;&nbsp;</a></span>AdaGrad()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr >
          <td class="memname"><a class="el" href="classmlpack_1_1optimization_1_1AdaGrad.html">AdaGrad</a> </td>
          <td >(</td>
          <td class="paramtype">const double&#160;</td>
          <td class="paramname"><em >stepSize</em> = <code >0.01</code>, </td>
        </tr>
        <tr >
          <td class="paramkey"></td>
          <td ></td>
          <td class="paramtype">const size_t&#160;</td>
          <td class="paramname"><em >batchSize</em> = <code >32</code>, </td>
        </tr>
        <tr >
          <td class="paramkey"></td>
          <td ></td>
          <td class="paramtype">const double&#160;</td>
          <td class="paramname"><em >epsilon</em> = <code >1e-8</code>, </td>
        </tr>
        <tr >
          <td class="paramkey"></td>
          <td ></td>
          <td class="paramtype">const size_t&#160;</td>
          <td class="paramname"><em >maxIterations</em> = <code >100000</code>, </td>
        </tr>
        <tr >
          <td class="paramkey"></td>
          <td ></td>
          <td class="paramtype">const double&#160;</td>
          <td class="paramname"><em >tolerance</em> = <code >1e-5</code>, </td>
        </tr>
        <tr >
          <td class="paramkey"></td>
          <td ></td>
          <td class="paramtype">const bool&#160;</td>
          <td class="paramname"><em >shuffle</em> = <code >true</code>&#160;</td>
        </tr>
        <tr >
          <td ></td>
          <td >)</td>
          <td ></td><td ></td>
        </tr>
      </table>
</div><div class="memdoc">

<p >Construct the <a class="el" href="classmlpack_1_1optimization_1_1AdaGrad.html" title="AdaGrad is a modified version of stochastic gradient descent which performs larger updates for more s...">AdaGrad</a> optimizer with the given function and parameters. </p>
<p >The defaults here are not necessarily good for the given problem, so it is suggested that the values used be tailored to the task at hand. The maximum number of iterations refers to the maximum number of points that are processed (i.e., one iteration equals one point; one iteration does not equal one pass over the dataset).</p>
<dl class="params"><dt >Parameters</dt><dd >
  <table class="params">
    <tr ><td class="paramname">stepSize</td><td >Step size for each iteration. </td></tr>
    <tr ><td class="paramname">batchSize</td><td >Number of points to process in one step. </td></tr>
    <tr ><td class="paramname">epsilon</td><td >Value used to initialise the squared gradient parameter. </td></tr>
    <tr ><td class="paramname">maxIterations</td><td >Maximum number of iterations allowed (0 means no limit). </td></tr>
    <tr ><td class="paramname">tolerance</td><td >Maximum absolute tolerance to terminate algorithm. </td></tr>
    <tr ><td class="paramname">shuffle</td><td >If true, the function order is shuffled; otherwise, each function is visited in linear order. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a7fc05cec06f55eb3c79d7f3f2fc197c5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7fc05cec06f55eb3c79d7f3f2fc197c5">&#9670;&nbsp;</a></span>BatchSize() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr >
  <td class="mlabels-left">
      <table class="memname">
        <tr >
          <td class="memname">size_t BatchSize </td>
          <td >(</td>
          <td class="paramname"></td><td >)</td>
          <td > const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p >Get the batch size. </p>

<p class="definition">Definition at line <a class="el" href="ada__grad_8hpp_source.html#l00113">113</a> of file <a class="el" href="ada__grad_8hpp_source.html">ada_grad.hpp</a>.</p>

</div>
</div>
<a id="abe6fa63561dedf6d88b7076d174e818f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abe6fa63561dedf6d88b7076d174e818f">&#9670;&nbsp;</a></span>BatchSize() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr >
  <td class="mlabels-left">
      <table class="memname">
        <tr >
          <td class="memname">size_t&amp; BatchSize </td>
          <td >(</td>
          <td class="paramname"></td><td >)</td>
          <td ></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p >Modify the batch size. </p>

<p class="definition">Definition at line <a class="el" href="ada__grad_8hpp_source.html#l00115">115</a> of file <a class="el" href="ada__grad_8hpp_source.html">ada_grad.hpp</a>.</p>

</div>
</div>
<a id="af6d960193bb5db37e51416e12bf720de"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af6d960193bb5db37e51416e12bf720de">&#9670;&nbsp;</a></span>Epsilon() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr >
  <td class="mlabels-left">
      <table class="memname">
        <tr >
          <td class="memname">double Epsilon </td>
          <td >(</td>
          <td class="paramname"></td><td >)</td>
          <td > const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p >Get the value used to initialise the squared gradient parameter. </p>

<p class="definition">Definition at line <a class="el" href="ada__grad_8hpp_source.html#l00118">118</a> of file <a class="el" href="ada__grad_8hpp_source.html">ada_grad.hpp</a>.</p>

</div>
</div>
<a id="ab6a080993b32456443eced5df2f8b9b9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab6a080993b32456443eced5df2f8b9b9">&#9670;&nbsp;</a></span>Epsilon() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr >
  <td class="mlabels-left">
      <table class="memname">
        <tr >
          <td class="memname">double&amp; Epsilon </td>
          <td >(</td>
          <td class="paramname"></td><td >)</td>
          <td ></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p >Modify the value used to initialise the squared gradient parameter. </p>

<p class="definition">Definition at line <a class="el" href="ada__grad_8hpp_source.html#l00120">120</a> of file <a class="el" href="ada__grad_8hpp_source.html">ada_grad.hpp</a>.</p>

</div>
</div>
<a id="a420770944a5b0c7a852c4ec372c4a2d1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a420770944a5b0c7a852c4ec372c4a2d1">&#9670;&nbsp;</a></span>MaxIterations() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr >
  <td class="mlabels-left">
      <table class="memname">
        <tr >
          <td class="memname">size_t MaxIterations </td>
          <td >(</td>
          <td class="paramname"></td><td >)</td>
          <td > const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p >Get the maximum number of iterations (0 indicates no limit). </p>

<p class="definition">Definition at line <a class="el" href="ada__grad_8hpp_source.html#l00123">123</a> of file <a class="el" href="ada__grad_8hpp_source.html">ada_grad.hpp</a>.</p>

</div>
</div>
<a id="acda675ab4ab86b95c92bc33bc391a61b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acda675ab4ab86b95c92bc33bc391a61b">&#9670;&nbsp;</a></span>MaxIterations() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr >
  <td class="mlabels-left">
      <table class="memname">
        <tr >
          <td class="memname">size_t&amp; MaxIterations </td>
          <td >(</td>
          <td class="paramname"></td><td >)</td>
          <td ></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p >Modify the maximum number of iterations (0 indicates no limit). </p>

<p class="definition">Definition at line <a class="el" href="ada__grad_8hpp_source.html#l00125">125</a> of file <a class="el" href="ada__grad_8hpp_source.html">ada_grad.hpp</a>.</p>

</div>
</div>
<a id="a99a6cd3d7b60bad439f79f99ec0118a7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a99a6cd3d7b60bad439f79f99ec0118a7">&#9670;&nbsp;</a></span>Optimize()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr >
  <td class="mlabels-left">
      <table class="memname">
        <tr >
          <td class="memname">double Optimize </td>
          <td >(</td>
          <td class="paramtype">DecomposableFunctionType &amp;&#160;</td>
          <td class="paramname"><em >function</em>, </td>
        </tr>
        <tr >
          <td class="paramkey"></td>
          <td ></td>
          <td class="paramtype">arma::mat &amp;&#160;</td>
          <td class="paramname"><em >iterate</em>&#160;</td>
        </tr>
        <tr >
          <td ></td>
          <td >)</td>
          <td ></td><td ></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p >Optimize the given function using <a class="el" href="classmlpack_1_1optimization_1_1AdaGrad.html" title="AdaGrad is a modified version of stochastic gradient descent which performs larger updates for more s...">AdaGrad</a>. </p>
<p >The given starting point will be modified to store the finishing point of the algorithm, and the final objective value is returned.</p>
<dl class="tparams"><dt >Template Parameters</dt><dd >
  <table class="tparams">
    <tr ><td class="paramname">DecomposableFunctionType</td><td >Type of the function to optimize. </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt >Parameters</dt><dd >
  <table class="params">
    <tr ><td class="paramname">function</td><td ><a class="el" href="classmlpack_1_1optimization_1_1Function.html" title="The Function class is a wrapper class for any FunctionType that will add any possible derived methods...">Function</a> to optimize. </td></tr>
    <tr ><td class="paramname">iterate</td><td >Starting point (will be modified). </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt >Returns</dt><dd >Objective value of the final point. </dd></dl>

<p class="definition">Definition at line <a class="el" href="ada__grad_8hpp_source.html#l00102">102</a> of file <a class="el" href="ada__grad_8hpp_source.html">ada_grad.hpp</a>.</p>

</div>
</div>
<a id="a3905e5cdf39697b4f82a1a53a087ef37"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3905e5cdf39697b4f82a1a53a087ef37">&#9670;&nbsp;</a></span>Shuffle() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr >
  <td class="mlabels-left">
      <table class="memname">
        <tr >
          <td class="memname">bool Shuffle </td>
          <td >(</td>
          <td class="paramname"></td><td >)</td>
          <td > const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p >Get whether or not the individual functions are shuffled. </p>

<p class="definition">Definition at line <a class="el" href="ada__grad_8hpp_source.html#l00133">133</a> of file <a class="el" href="ada__grad_8hpp_source.html">ada_grad.hpp</a>.</p>

</div>
</div>
<a id="af374b2359713783f431ab1238dc524f3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af374b2359713783f431ab1238dc524f3">&#9670;&nbsp;</a></span>Shuffle() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr >
  <td class="mlabels-left">
      <table class="memname">
        <tr >
          <td class="memname">bool&amp; Shuffle </td>
          <td >(</td>
          <td class="paramname"></td><td >)</td>
          <td ></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p >Modify whether or not the individual functions are shuffled. </p>

<p class="definition">Definition at line <a class="el" href="ada__grad_8hpp_source.html#l00135">135</a> of file <a class="el" href="ada__grad_8hpp_source.html">ada_grad.hpp</a>.</p>

</div>
</div>
<a id="a11e6eb66d82a14ebd2943b49db676444"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a11e6eb66d82a14ebd2943b49db676444">&#9670;&nbsp;</a></span>StepSize() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr >
  <td class="mlabels-left">
      <table class="memname">
        <tr >
          <td class="memname">double StepSize </td>
          <td >(</td>
          <td class="paramname"></td><td >)</td>
          <td > const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p >Get the step size. </p>

<p class="definition">Definition at line <a class="el" href="ada__grad_8hpp_source.html#l00108">108</a> of file <a class="el" href="ada__grad_8hpp_source.html">ada_grad.hpp</a>.</p>

</div>
</div>
<a id="af6b273aba48a984b2847aa1593e09477"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af6b273aba48a984b2847aa1593e09477">&#9670;&nbsp;</a></span>StepSize() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr >
  <td class="mlabels-left">
      <table class="memname">
        <tr >
          <td class="memname">double&amp; StepSize </td>
          <td >(</td>
          <td class="paramname"></td><td >)</td>
          <td ></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p >Modify the step size. </p>

<p class="definition">Definition at line <a class="el" href="ada__grad_8hpp_source.html#l00110">110</a> of file <a class="el" href="ada__grad_8hpp_source.html">ada_grad.hpp</a>.</p>

</div>
</div>
<a id="a7b5af5c1a84c507cbaa7f999ea5a4fda"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7b5af5c1a84c507cbaa7f999ea5a4fda">&#9670;&nbsp;</a></span>Tolerance() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr >
  <td class="mlabels-left">
      <table class="memname">
        <tr >
          <td class="memname">double Tolerance </td>
          <td >(</td>
          <td class="paramname"></td><td >)</td>
          <td > const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p >Get the tolerance for termination. </p>

<p class="definition">Definition at line <a class="el" href="ada__grad_8hpp_source.html#l00128">128</a> of file <a class="el" href="ada__grad_8hpp_source.html">ada_grad.hpp</a>.</p>

</div>
</div>
<a id="a3d9fac84af16250f5a3689692e8f2173"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3d9fac84af16250f5a3689692e8f2173">&#9670;&nbsp;</a></span>Tolerance() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr >
  <td class="mlabels-left">
      <table class="memname">
        <tr >
          <td class="memname">double&amp; Tolerance </td>
          <td >(</td>
          <td class="paramname"></td><td >)</td>
          <td ></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p >Modify the tolerance for termination. </p>

<p class="definition">Definition at line <a class="el" href="ada__grad_8hpp_source.html#l00130">130</a> of file <a class="el" href="ada__grad_8hpp_source.html">ada_grad.hpp</a>.</p>

</div>
</div>
<hr ></hr>The documentation for this class was generated from the following file:<ul >
<li >src/mlpack/core/optimizers/ada_grad/<a class="el" href="ada__grad_8hpp_source.html">ada_grad.hpp</a></li>
</ul>
</div>

<hr class="footer"></hr><address class="footer"><small >
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"></img>
</a> 1.8.13
</small></address>
</div>
</body>
<script type="text/javascript">
var x = document.querySelectorAll("img.formulaDsp");
var i;
for (i = 0; i < x.length; i++)
{
  x[i].width = x[i].offsetWidth / 4;
}
</script>
</html>