<html >
<head >

<meta name="keywords" content="mlpack, libmlpack, c++, armadillo, machine
learning, data mining, classification, regression, tree-based methods, dual-tree
algorithm">
<meta name="description" content="mlpack: a scalable c++ machine learning
library">
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title >mlpack: a scalable c++ machine learning library</title>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript" src="dynamic_tables.js"></script>
</head><link rel="stylesheet" href="style-doxygen.css" /><link rel="stylesheet" href="doxygen.css" /><link rel="stylesheet" href="tabs.css" /><link rel="stylesheet" href="search/search.css" /><link href="http://fonts.googleapis.com/css?family=Maven+Pro:500" rel="stylesheet" type="text/css" />





<body ><br />


<div class="mlpack_titlebar">
   <a href="http://www.mlpack.org"><img src="../../../mlpack.png"></a>
</div>
<center >
<div class="mlnavbar">
  <div class="navcontainer">
   <div class="mlnavitem" name="mlnavmain"><a href="../../../index.html">main</a></div>
   <div class="mlnavitem" name="mlnavabout"><a href="../../../about.html">about</a></div>
   <div class="mlnavitem" name="mlnavdoc"><a href="../../../docs.html">docs</a></div>
   <div class="mlnavitem" name="mlnavhelp"><a href="../../../help.html">get help</a></div>
   <div class="mlnavitem" name="mlnavbugs"><a href="https://github.com/mlpack/mlpack">github</a></div>
  </div>
</div>
</center>
<div class="separator"></div>
<center >
<div class="mainsection smallertext">
<div id="top">
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody >
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">mlpack
   &#160;<span id="projectnumber">master</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>

<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>

<div id="MSearchSelectWindow" onmouseover="return searchBox.OnSearchSelectShow()" onmouseout="return searchBox.OnSearchSelectHide()" onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>


<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul >
<li class="navelem"><a class="el" href="dir_68267d1309a1af8e8297ef4c3efbcdba.html">src</a></li><li class="navelem"><a class="el" href="dir_44a936ef30fc126706c6284a2fc0c990.html">mlpack</a></li><li class="navelem"><a class="el" href="dir_f7ac9cdfd28b2e882eb44d163e3b98b4.html">core</a></li><li class="navelem"><a class="el" href="dir_c92267e6eea9957c44bb2efde721ca22.html">optimizers</a></li><li class="navelem"><a class="el" href="dir_51394de836c4db81de5c4afe3d23e7c7.html">ada_grad</a></li>  </ul>
</div>
</div>
<div class="header">
  <div class="headertitle">
<div class="title">ada_grad.hpp</div>  </div>
</div>
<div class="contents">
<a href="ada__grad_8hpp.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;</div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;<span class="preprocessor">#ifndef MLPACK_CORE_OPTIMIZERS_ADA_GRAD_ADA_GRAD_HPP</span></div><div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;<span class="preprocessor">#define MLPACK_CORE_OPTIMIZERS_ADA_GRAD_ADA_GRAD_HPP</span></div><div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;</div><div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;<span class="preprocessor">#include &lt;<a class="code" href="prereqs_8hpp.html">mlpack/prereqs.hpp</a>&gt;</span></div><div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;<span class="preprocessor">#include &lt;<a class="code" href="sgd_8hpp.html">mlpack/core/optimizers/sgd/sgd.hpp</a>&gt;</span></div><div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="ada__grad__update_8hpp.html">ada_grad_update.hpp</a>&quot;</span></div><div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;</div><div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;<span class="keyword">namespace </span><a class="code" href="namespacemlpack.html">mlpack</a> {</div><div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;<span class="keyword">namespace </span>optimization {</div><div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;</div><div class="line"><a name="l00060"></a><span class="lineno"><a class="line" href="classmlpack_1_1optimization_1_1AdaGrad.html">   60</a></span>&#160;<span class="keyword">class </span><a class="code" href="classmlpack_1_1optimization_1_1AdaGrad.html">AdaGrad</a></div><div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;{</div><div class="line"><a name="l00062"></a><span class="lineno">   62</span>&#160; <span class="keyword">public</span>:</div><div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;  <a class="code" href="classmlpack_1_1optimization_1_1AdaGrad.html#a4c94999120b0340f2f7e46e6fe58a331">AdaGrad</a>(<span class="keyword">const</span> <span class="keywordtype">double</span> stepSize = 0.01,</div><div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;          <span class="keyword">const</span> <span class="keywordtype">double</span> epsilon = 1e-8,</div><div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;          <span class="keyword">const</span> <span class="keywordtype">size_t</span> maxIterations = 100000,</div><div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;          <span class="keyword">const</span> <span class="keywordtype">double</span> tolerance = 1e-5,</div><div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;          <span class="keyword">const</span> <span class="keywordtype">bool</span> shuffle = <span class="keyword">true</span>);</div><div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;</div><div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;  <span class="keyword">template</span>&lt;<span class="keyword">typename</span> DecomposableFunctionType&gt;</div><div class="line"><a name="l00096"></a><span class="lineno"><a class="line" href="classmlpack_1_1optimization_1_1AdaGrad.html#a99a6cd3d7b60bad439f79f99ec0118a7">   96</a></span>&#160;  <span class="keywordtype">double</span> <a class="code" href="classmlpack_1_1optimization_1_1AdaGrad.html#a99a6cd3d7b60bad439f79f99ec0118a7">Optimize</a>(DecomposableFunctionType&amp; <span class="keyword">function</span>, arma::mat&amp; iterate)</div><div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;  {</div><div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;    <span class="keywordflow">return</span> optimizer.Optimize(<span class="keyword">function</span>, iterate);</div><div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;  }</div><div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;</div><div class="line"><a name="l00102"></a><span class="lineno"><a class="line" href="classmlpack_1_1optimization_1_1AdaGrad.html#a11e6eb66d82a14ebd2943b49db676444">  102</a></span>&#160;  <span class="keywordtype">double</span> <a class="code" href="classmlpack_1_1optimization_1_1AdaGrad.html#a11e6eb66d82a14ebd2943b49db676444">StepSize</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> optimizer.StepSize(); }</div><div class="line"><a name="l00104"></a><span class="lineno"><a class="line" href="classmlpack_1_1optimization_1_1AdaGrad.html#af6b273aba48a984b2847aa1593e09477">  104</a></span>&#160;  <span class="keywordtype">double</span>&amp; <a class="code" href="classmlpack_1_1optimization_1_1AdaGrad.html#af6b273aba48a984b2847aa1593e09477">StepSize</a>() { <span class="keywordflow">return</span> optimizer.StepSize(); }</div><div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160;</div><div class="line"><a name="l00107"></a><span class="lineno"><a class="line" href="classmlpack_1_1optimization_1_1AdaGrad.html#af6d960193bb5db37e51416e12bf720de">  107</a></span>&#160;  <span class="keywordtype">double</span> <a class="code" href="classmlpack_1_1optimization_1_1AdaGrad.html#af6d960193bb5db37e51416e12bf720de">Epsilon</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> optimizer.UpdatePolicy().Epsilon(); }</div><div class="line"><a name="l00109"></a><span class="lineno"><a class="line" href="classmlpack_1_1optimization_1_1AdaGrad.html#ab6a080993b32456443eced5df2f8b9b9">  109</a></span>&#160;  <span class="keywordtype">double</span>&amp; <a class="code" href="classmlpack_1_1optimization_1_1AdaGrad.html#ab6a080993b32456443eced5df2f8b9b9">Epsilon</a>() { <span class="keywordflow">return</span> optimizer.UpdatePolicy().Epsilon(); }</div><div class="line"><a name="l00110"></a><span class="lineno">  110</span>&#160;</div><div class="line"><a name="l00112"></a><span class="lineno"><a class="line" href="classmlpack_1_1optimization_1_1AdaGrad.html#a420770944a5b0c7a852c4ec372c4a2d1">  112</a></span>&#160;  <span class="keywordtype">size_t</span> <a class="code" href="classmlpack_1_1optimization_1_1AdaGrad.html#a420770944a5b0c7a852c4ec372c4a2d1">MaxIterations</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> optimizer.MaxIterations(); }</div><div class="line"><a name="l00114"></a><span class="lineno"><a class="line" href="classmlpack_1_1optimization_1_1AdaGrad.html#acda675ab4ab86b95c92bc33bc391a61b">  114</a></span>&#160;  <span class="keywordtype">size_t</span>&amp; <a class="code" href="classmlpack_1_1optimization_1_1AdaGrad.html#acda675ab4ab86b95c92bc33bc391a61b">MaxIterations</a>() { <span class="keywordflow">return</span> optimizer.MaxIterations(); }</div><div class="line"><a name="l00115"></a><span class="lineno">  115</span>&#160;</div><div class="line"><a name="l00117"></a><span class="lineno"><a class="line" href="classmlpack_1_1optimization_1_1AdaGrad.html#a7b5af5c1a84c507cbaa7f999ea5a4fda">  117</a></span>&#160;  <span class="keywordtype">double</span> <a class="code" href="classmlpack_1_1optimization_1_1AdaGrad.html#a7b5af5c1a84c507cbaa7f999ea5a4fda">Tolerance</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> optimizer.Tolerance(); }</div><div class="line"><a name="l00119"></a><span class="lineno"><a class="line" href="classmlpack_1_1optimization_1_1AdaGrad.html#a3d9fac84af16250f5a3689692e8f2173">  119</a></span>&#160;  <span class="keywordtype">double</span>&amp; <a class="code" href="classmlpack_1_1optimization_1_1AdaGrad.html#a3d9fac84af16250f5a3689692e8f2173">Tolerance</a>() { <span class="keywordflow">return</span> optimizer.Tolerance(); }</div><div class="line"><a name="l00120"></a><span class="lineno">  120</span>&#160;</div><div class="line"><a name="l00122"></a><span class="lineno"><a class="line" href="classmlpack_1_1optimization_1_1AdaGrad.html#a3905e5cdf39697b4f82a1a53a087ef37">  122</a></span>&#160;  <span class="keywordtype">bool</span> <a class="code" href="classmlpack_1_1optimization_1_1AdaGrad.html#a3905e5cdf39697b4f82a1a53a087ef37">Shuffle</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> optimizer.Shuffle(); }</div><div class="line"><a name="l00124"></a><span class="lineno"><a class="line" href="classmlpack_1_1optimization_1_1AdaGrad.html#af374b2359713783f431ab1238dc524f3">  124</a></span>&#160;  <span class="keywordtype">bool</span>&amp; <a class="code" href="classmlpack_1_1optimization_1_1AdaGrad.html#af374b2359713783f431ab1238dc524f3">Shuffle</a>() { <span class="keywordflow">return</span> optimizer.Shuffle(); }</div><div class="line"><a name="l00125"></a><span class="lineno">  125</span>&#160;</div><div class="line"><a name="l00126"></a><span class="lineno">  126</span>&#160; <span class="keyword">private</span>:</div><div class="line"><a name="l00128"></a><span class="lineno">  128</span>&#160;  <a class="code" href="classmlpack_1_1optimization_1_1SGD.html">SGD&lt;AdaGradUpdate&gt;</a> optimizer;</div><div class="line"><a name="l00129"></a><span class="lineno">  129</span>&#160;};</div><div class="line"><a name="l00130"></a><span class="lineno">  130</span>&#160;</div><div class="line"><a name="l00131"></a><span class="lineno">  131</span>&#160;} <span class="comment">// namespace optimization</span></div><div class="line"><a name="l00132"></a><span class="lineno">  132</span>&#160;} <span class="comment">// namespace mlpack</span></div><div class="line"><a name="l00133"></a><span class="lineno">  133</span>&#160;</div><div class="line"><a name="l00134"></a><span class="lineno">  134</span>&#160;<span class="preprocessor">#endif</span></div><div class="ttc" id="classmlpack_1_1optimization_1_1AdaGrad_html_a99a6cd3d7b60bad439f79f99ec0118a7"><div class="ttname"><a href="classmlpack_1_1optimization_1_1AdaGrad.html#a99a6cd3d7b60bad439f79f99ec0118a7">mlpack::optimization::AdaGrad::Optimize</a></div><div class="ttdeci">double Optimize(DecomposableFunctionType &amp;function, arma::mat &amp;iterate)</div><div class="ttdoc">Optimize the given function using AdaGrad. </div><div class="ttdef"><b >Definition:</b> <a href="ada__grad_8hpp_source.html#l00096">ada_grad.hpp:96</a></div></div>
<div class="ttc" id="namespacemlpack_html"><div class="ttname"><a href="namespacemlpack.html">mlpack</a></div><div class="ttdoc">Linear algebra utility functions, generally performed on matrices or vectors. </div><div class="ttdef"><b >Definition:</b> <a href="add__to__po_8hpp_source.html#l00016">add_to_po.hpp:16</a></div></div>
<div class="ttc" id="classmlpack_1_1optimization_1_1AdaGrad_html_ab6a080993b32456443eced5df2f8b9b9"><div class="ttname"><a href="classmlpack_1_1optimization_1_1AdaGrad.html#ab6a080993b32456443eced5df2f8b9b9">mlpack::optimization::AdaGrad::Epsilon</a></div><div class="ttdeci">double &amp; Epsilon()</div><div class="ttdoc">Modify the value used to initialise the squared gradient parameter. </div><div class="ttdef"><b >Definition:</b> <a href="ada__grad_8hpp_source.html#l00109">ada_grad.hpp:109</a></div></div>
<div class="ttc" id="prereqs_8hpp_html"><div class="ttname"><a href="prereqs_8hpp.html">prereqs.hpp</a></div><div class="ttdoc">The core includes that mlpack expects; standard C++ includes and Armadillo. </div></div>
<div class="ttc" id="ada__grad__update_8hpp_html"><div class="ttname"><a href="ada__grad__update_8hpp.html">ada_grad_update.hpp</a></div></div>
<div class="ttc" id="classmlpack_1_1optimization_1_1AdaGrad_html_a3d9fac84af16250f5a3689692e8f2173"><div class="ttname"><a href="classmlpack_1_1optimization_1_1AdaGrad.html#a3d9fac84af16250f5a3689692e8f2173">mlpack::optimization::AdaGrad::Tolerance</a></div><div class="ttdeci">double &amp; Tolerance()</div><div class="ttdoc">Modify the tolerance for termination. </div><div class="ttdef"><b >Definition:</b> <a href="ada__grad_8hpp_source.html#l00119">ada_grad.hpp:119</a></div></div>
<div class="ttc" id="classmlpack_1_1optimization_1_1AdaGrad_html_af6b273aba48a984b2847aa1593e09477"><div class="ttname"><a href="classmlpack_1_1optimization_1_1AdaGrad.html#af6b273aba48a984b2847aa1593e09477">mlpack::optimization::AdaGrad::StepSize</a></div><div class="ttdeci">double &amp; StepSize()</div><div class="ttdoc">Modify the step size. </div><div class="ttdef"><b >Definition:</b> <a href="ada__grad_8hpp_source.html#l00104">ada_grad.hpp:104</a></div></div>
<div class="ttc" id="classmlpack_1_1optimization_1_1AdaGrad_html_a420770944a5b0c7a852c4ec372c4a2d1"><div class="ttname"><a href="classmlpack_1_1optimization_1_1AdaGrad.html#a420770944a5b0c7a852c4ec372c4a2d1">mlpack::optimization::AdaGrad::MaxIterations</a></div><div class="ttdeci">size_t MaxIterations() const</div><div class="ttdoc">Get the maximum number of iterations (0 indicates no limit). </div><div class="ttdef"><b >Definition:</b> <a href="ada__grad_8hpp_source.html#l00112">ada_grad.hpp:112</a></div></div>
<div class="ttc" id="sgd_8hpp_html"><div class="ttname"><a href="sgd_8hpp.html">sgd.hpp</a></div></div>
<div class="ttc" id="classmlpack_1_1optimization_1_1AdaGrad_html"><div class="ttname"><a href="classmlpack_1_1optimization_1_1AdaGrad.html">mlpack::optimization::AdaGrad</a></div><div class="ttdoc">AdaGrad is a modified version of stochastic gradient descent which performs larger updates for more s...</div><div class="ttdef"><b >Definition:</b> <a href="ada__grad_8hpp_source.html#l00060">ada_grad.hpp:60</a></div></div>
<div class="ttc" id="classmlpack_1_1optimization_1_1AdaGrad_html_af6d960193bb5db37e51416e12bf720de"><div class="ttname"><a href="classmlpack_1_1optimization_1_1AdaGrad.html#af6d960193bb5db37e51416e12bf720de">mlpack::optimization::AdaGrad::Epsilon</a></div><div class="ttdeci">double Epsilon() const</div><div class="ttdoc">Get the value used to initialise the squared gradient parameter. </div><div class="ttdef"><b >Definition:</b> <a href="ada__grad_8hpp_source.html#l00107">ada_grad.hpp:107</a></div></div>
<div class="ttc" id="classmlpack_1_1optimization_1_1AdaGrad_html_a7b5af5c1a84c507cbaa7f999ea5a4fda"><div class="ttname"><a href="classmlpack_1_1optimization_1_1AdaGrad.html#a7b5af5c1a84c507cbaa7f999ea5a4fda">mlpack::optimization::AdaGrad::Tolerance</a></div><div class="ttdeci">double Tolerance() const</div><div class="ttdoc">Get the tolerance for termination. </div><div class="ttdef"><b >Definition:</b> <a href="ada__grad_8hpp_source.html#l00117">ada_grad.hpp:117</a></div></div>
<div class="ttc" id="classmlpack_1_1optimization_1_1SGD_html"><div class="ttname"><a href="classmlpack_1_1optimization_1_1SGD.html">mlpack::optimization::SGD</a></div><div class="ttdoc">Stochastic Gradient Descent is a technique for minimizing a function which can be expressed as a sum ...</div><div class="ttdef"><b >Definition:</b> <a href="sgd_8hpp_source.html#l00078">sgd.hpp:78</a></div></div>
<div class="ttc" id="classmlpack_1_1optimization_1_1AdaGrad_html_a11e6eb66d82a14ebd2943b49db676444"><div class="ttname"><a href="classmlpack_1_1optimization_1_1AdaGrad.html#a11e6eb66d82a14ebd2943b49db676444">mlpack::optimization::AdaGrad::StepSize</a></div><div class="ttdeci">double StepSize() const</div><div class="ttdoc">Get the step size. </div><div class="ttdef"><b >Definition:</b> <a href="ada__grad_8hpp_source.html#l00102">ada_grad.hpp:102</a></div></div>
<div class="ttc" id="classmlpack_1_1optimization_1_1AdaGrad_html_a4c94999120b0340f2f7e46e6fe58a331"><div class="ttname"><a href="classmlpack_1_1optimization_1_1AdaGrad.html#a4c94999120b0340f2f7e46e6fe58a331">mlpack::optimization::AdaGrad::AdaGrad</a></div><div class="ttdeci">AdaGrad(const double stepSize=0.01, const double epsilon=1e-8, const size_t maxIterations=100000, const double tolerance=1e-5, const bool shuffle=true)</div><div class="ttdoc">Construct the AdaGrad optimizer with the given function and parameters. </div></div>
<div class="ttc" id="classmlpack_1_1optimization_1_1AdaGrad_html_a3905e5cdf39697b4f82a1a53a087ef37"><div class="ttname"><a href="classmlpack_1_1optimization_1_1AdaGrad.html#a3905e5cdf39697b4f82a1a53a087ef37">mlpack::optimization::AdaGrad::Shuffle</a></div><div class="ttdeci">bool Shuffle() const</div><div class="ttdoc">Get whether or not the individual functions are shuffled. </div><div class="ttdef"><b >Definition:</b> <a href="ada__grad_8hpp_source.html#l00122">ada_grad.hpp:122</a></div></div>
<div class="ttc" id="classmlpack_1_1optimization_1_1AdaGrad_html_af374b2359713783f431ab1238dc524f3"><div class="ttname"><a href="classmlpack_1_1optimization_1_1AdaGrad.html#af374b2359713783f431ab1238dc524f3">mlpack::optimization::AdaGrad::Shuffle</a></div><div class="ttdeci">bool &amp; Shuffle()</div><div class="ttdoc">Modify whether or not the individual functions are shuffled. </div><div class="ttdef"><b >Definition:</b> <a href="ada__grad_8hpp_source.html#l00124">ada_grad.hpp:124</a></div></div>
<div class="ttc" id="classmlpack_1_1optimization_1_1AdaGrad_html_acda675ab4ab86b95c92bc33bc391a61b"><div class="ttname"><a href="classmlpack_1_1optimization_1_1AdaGrad.html#acda675ab4ab86b95c92bc33bc391a61b">mlpack::optimization::AdaGrad::MaxIterations</a></div><div class="ttdeci">size_t &amp; MaxIterations()</div><div class="ttdoc">Modify the maximum number of iterations (0 indicates no limit). </div><div class="ttdef"><b >Definition:</b> <a href="ada__grad_8hpp_source.html#l00114">ada_grad.hpp:114</a></div></div>
</div></div>

<hr class="footer"></hr><address class="footer"><small >
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"></img>
</a> 1.8.13
</small></address>
</div>
</body>
<script type="text/javascript">
var x = document.querySelectorAll("img.formulaDsp");
var i;
for (i = 0; i < x.length; i++)
{
  x[i].width = x[i].offsetWidth / 4;
}
</script>
</html>