<html >
<head >

<meta name="keywords" content="mlpack, libmlpack, c++, armadillo, machine
learning, data mining, classification, regression, tree-based methods, dual-tree
algorithm">
<meta name="description" content="mlpack: a scalable c++ machine learning
library">
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title >mlpack: a scalable c++ machine learning library</title>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript" src="dynamic_tables.js"></script>
</head><link rel="stylesheet" href="style-doxygen.css" /><link rel="stylesheet" href="doxygen.css" /><link rel="stylesheet" href="tabs.css" /><link rel="stylesheet" href="search/search.css" /><link href="http://fonts.googleapis.com/css?family=Maven+Pro:500" rel="stylesheet" type="text/css" />





<body ><br />


<div class="mlpack_titlebar">
   <a href="http://www.mlpack.org"><img src="../../../mlpack.png"></a>
</div>
<center >
<div class="mlnavbar">
  <div class="navcontainer">
   <div class="mlnavitem" name="mlnavmain"><a href="../../../index.html">main</a></div>
   <div class="mlnavitem" name="mlnavabout"><a href="../../../about.html">about</a></div>
   <div class="mlnavitem" name="mlnavdoc"><a href="../../../docs.html">docs</a></div>
   <div class="mlnavitem" name="mlnavhelp"><a href="../../../help.html">get help</a></div>
   <div class="mlnavitem" name="mlnavbugs"><a href="https://github.com/mlpack/mlpack">github</a></div>
  </div>
</div>
</center>
<div class="separator"></div>
<center >
<div class="mainsection smallertext">
<div id="top">
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody >
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">mlpack
   &#160;<span id="projectnumber">master</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>

<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>

<div id="MSearchSelectWindow" onmouseover="return searchBox.OnSearchSelectShow()" onmouseout="return searchBox.OnSearchSelectHide()" onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>


<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul >
<li class="navelem"><a class="el" href="namespacemlpack.html">mlpack</a></li><li class="navelem"><a class="el" href="namespacemlpack_1_1ann.html">ann</a></li><li class="navelem"><a class="el" href="classmlpack_1_1ann_1_1FFN.html">FFN</a></li>  </ul>
</div>
</div>
<div class="header">
  <div class="summary">
<a href="#pub-types">Public Types</a> &#124;
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="classmlpack_1_1ann_1_1FFN-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">FFN&lt; OutputLayerType, InitializationRuleType &gt; Class Template Reference</div>  </div>
</div>
<div class="contents">

<p >Implementation of a standard feed forward network.  
 <a href="classmlpack_1_1ann_1_1FFN.html#details">More...</a></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-types"></a>
Public Types</h2></td></tr>
<tr class="memitem:aa628987cefe24b56f3c1551d0588a329"><td class="memItemLeft" align="right" valign="top">using&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1ann_1_1FFN.html#aa628987cefe24b56f3c1551d0588a329">NetworkType</a> = <a class="el" href="classmlpack_1_1ann_1_1FFN.html">FFN</a>&lt; OutputLayerType, InitializationRuleType &gt;</td></tr>
<tr class="memdesc:aa628987cefe24b56f3c1551d0588a329"><td class="mdescLeft">&#160;</td><td class="mdescRight">Convenience typedef for the internal model construction.  <a href="#aa628987cefe24b56f3c1551d0588a329">More...</a><br /></br></td></tr>
<tr class="separator:aa628987cefe24b56f3c1551d0588a329"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a8a1597bba65304f53ae1cecd73b395a6"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1ann_1_1FFN.html#a8a1597bba65304f53ae1cecd73b395a6">FFN</a> (OutputLayerType outputLayer=OutputLayerType(), InitializationRuleType initializeRule=InitializationRuleType())</td></tr>
<tr class="memdesc:a8a1597bba65304f53ae1cecd73b395a6"><td class="mdescLeft">&#160;</td><td class="mdescRight">Create the <a class="el" href="classmlpack_1_1ann_1_1FFN.html" title="Implementation of a standard feed forward network. ">FFN</a> object with the given predictors and responses set (this is the set that is used to train the network).  <a href="#a8a1597bba65304f53ae1cecd73b395a6">More...</a><br /></br></td></tr>
<tr class="separator:a8a1597bba65304f53ae1cecd73b395a6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a747c838260bf79c9b08e310660792800"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1ann_1_1FFN.html#a747c838260bf79c9b08e310660792800">FFN</a> (const <a class="el" href="classmlpack_1_1ann_1_1FFN.html">FFN</a> &amp;)</td></tr>
<tr class="memdesc:a747c838260bf79c9b08e310660792800"><td class="mdescLeft">&#160;</td><td class="mdescRight">Copy constructor.  <a href="#a747c838260bf79c9b08e310660792800">More...</a><br /></br></td></tr>
<tr class="separator:a747c838260bf79c9b08e310660792800"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8aa14d013d2855c06df5d78b31a126ef"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1ann_1_1FFN.html#a8aa14d013d2855c06df5d78b31a126ef">FFN</a> (<a class="el" href="classmlpack_1_1ann_1_1FFN.html">FFN</a> &amp;&amp;)</td></tr>
<tr class="memdesc:a8aa14d013d2855c06df5d78b31a126ef"><td class="mdescLeft">&#160;</td><td class="mdescRight">Move constructor.  <a href="#a8aa14d013d2855c06df5d78b31a126ef">More...</a><br /></br></td></tr>
<tr class="separator:a8aa14d013d2855c06df5d78b31a126ef"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a11cb0ca52a8fb7e342d75582c7c5b262"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1ann_1_1FFN.html#a11cb0ca52a8fb7e342d75582c7c5b262">FFN</a> (arma::mat predictors, arma::mat responses, OutputLayerType outputLayer=OutputLayerType(), InitializationRuleType initializeRule=InitializationRuleType())</td></tr>
<tr class="memdesc:a11cb0ca52a8fb7e342d75582c7c5b262"><td class="mdescLeft">&#160;</td><td class="mdescRight">Create the <a class="el" href="classmlpack_1_1ann_1_1FFN.html" title="Implementation of a standard feed forward network. ">FFN</a> object with the given predictors and responses set (this is the set that is used to train the network).  <a href="#a11cb0ca52a8fb7e342d75582c7c5b262">More...</a><br /></br></td></tr>
<tr class="separator:a11cb0ca52a8fb7e342d75582c7c5b262"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a45450c5c89a5be407cbaa16523c1533d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1ann_1_1FFN.html#a45450c5c89a5be407cbaa16523c1533d">~FFN</a> ()</td></tr>
<tr class="memdesc:a45450c5c89a5be407cbaa16523c1533d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Destructor to release allocated memory.  <a href="#a45450c5c89a5be407cbaa16523c1533d">More...</a><br /></br></td></tr>
<tr class="separator:a45450c5c89a5be407cbaa16523c1533d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8b5234495846c00f6b2c8296ca6bc718"><td class="memTemplParams" colspan="2">template&lt;class LayerType , class... Args&gt; </td></tr>
<tr class="memitem:a8b5234495846c00f6b2c8296ca6bc718"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classmlpack_1_1ann_1_1FFN.html#a8b5234495846c00f6b2c8296ca6bc718">Add</a> (Args... args)</td></tr>
<tr class="separator:a8b5234495846c00f6b2c8296ca6bc718"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a463090e0ef9decba7abee503cc3afc06"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1ann_1_1FFN.html#a463090e0ef9decba7abee503cc3afc06">Add</a> (<a class="el" href="namespacemlpack_1_1ann.html#a427481f2eba15f51860d5a225a56d8ac">LayerTypes</a> layer)</td></tr>
<tr class="separator:a463090e0ef9decba7abee503cc3afc06"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0b003a392c76e36fe5d9c71d635c49ea"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1ann_1_1FFN.html#a0b003a392c76e36fe5d9c71d635c49ea">Backward</a> (arma::mat targets, arma::mat &amp;gradients)</td></tr>
<tr class="memdesc:a0b003a392c76e36fe5d9c71d635c49ea"><td class="mdescLeft">&#160;</td><td class="mdescRight">Perform the backward pass of the data in real batch mode.  <a href="#a0b003a392c76e36fe5d9c71d635c49ea">More...</a><br /></br></td></tr>
<tr class="separator:a0b003a392c76e36fe5d9c71d635c49ea"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac9498204c7e2b9546c00f3cf55d9879c"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1ann_1_1FFN.html#ac9498204c7e2b9546c00f3cf55d9879c">Evaluate</a> (const arma::mat &amp;parameters, const size_t i, const bool deterministic=true)</td></tr>
<tr class="memdesc:ac9498204c7e2b9546c00f3cf55d9879c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Evaluate the feedforward network with the given parameters, but using only one data point.  <a href="#ac9498204c7e2b9546c00f3cf55d9879c">More...</a><br /></br></td></tr>
<tr class="separator:ac9498204c7e2b9546c00f3cf55d9879c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1ca0efaedbc2e7e7542c89901cdcf2ee"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1ann_1_1FFN.html#a1ca0efaedbc2e7e7542c89901cdcf2ee">Evaluate</a> (const arma::mat &amp;parameters)</td></tr>
<tr class="memdesc:a1ca0efaedbc2e7e7542c89901cdcf2ee"><td class="mdescLeft">&#160;</td><td class="mdescRight">Evaluate the feedforward network with the given parameters.  <a href="#a1ca0efaedbc2e7e7542c89901cdcf2ee">More...</a><br /></br></td></tr>
<tr class="separator:a1ca0efaedbc2e7e7542c89901cdcf2ee"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae072bd97493974f32b5a738fc8803c93"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1ann_1_1FFN.html#ae072bd97493974f32b5a738fc8803c93">Forward</a> (arma::mat inputs, arma::mat &amp;results)</td></tr>
<tr class="memdesc:ae072bd97493974f32b5a738fc8803c93"><td class="mdescLeft">&#160;</td><td class="mdescRight">Perform the forward pass of the data in real batch mode.  <a href="#ae072bd97493974f32b5a738fc8803c93">More...</a><br /></br></td></tr>
<tr class="separator:ae072bd97493974f32b5a738fc8803c93"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a71b4d1c08d05fb5219e600e4e6b07f18"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1ann_1_1FFN.html#a71b4d1c08d05fb5219e600e4e6b07f18">Gradient</a> (const arma::mat &amp;parameters, const size_t i, arma::mat &amp;gradient)</td></tr>
<tr class="memdesc:a71b4d1c08d05fb5219e600e4e6b07f18"><td class="mdescLeft">&#160;</td><td class="mdescRight">Evaluate the gradient of the feedforward network with the given parameters, and with respect to only one point in the dataset.  <a href="#a71b4d1c08d05fb5219e600e4e6b07f18">More...</a><br /></br></td></tr>
<tr class="separator:a71b4d1c08d05fb5219e600e4e6b07f18"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1fa76af34a6e3ea927b307f0c318ee4b"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1ann_1_1FFN.html#a1fa76af34a6e3ea927b307f0c318ee4b">NumFunctions</a> () const</td></tr>
<tr class="memdesc:a1fa76af34a6e3ea927b307f0c318ee4b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Return the number of separable functions (the number of predictor points).  <a href="#a1fa76af34a6e3ea927b307f0c318ee4b">More...</a><br /></br></td></tr>
<tr class="separator:a1fa76af34a6e3ea927b307f0c318ee4b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad3218e6a988d7203fd6a0ced3e457057"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classmlpack_1_1ann_1_1FFN.html">FFN</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1ann_1_1FFN.html#ad3218e6a988d7203fd6a0ced3e457057">operator=</a> (<a class="el" href="classmlpack_1_1ann_1_1FFN.html">FFN</a>)</td></tr>
<tr class="memdesc:ad3218e6a988d7203fd6a0ced3e457057"><td class="mdescLeft">&#160;</td><td class="mdescRight">Copy/move assignment operator.  <a href="#ad3218e6a988d7203fd6a0ced3e457057">More...</a><br /></br></td></tr>
<tr class="separator:ad3218e6a988d7203fd6a0ced3e457057"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa68d74dc1e86e4352e00a3cab83a0e4a"><td class="memItemLeft" align="right" valign="top">const arma::mat &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1ann_1_1FFN.html#aa68d74dc1e86e4352e00a3cab83a0e4a">Parameters</a> () const</td></tr>
<tr class="memdesc:aa68d74dc1e86e4352e00a3cab83a0e4a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Return the initial point for the optimization.  <a href="#aa68d74dc1e86e4352e00a3cab83a0e4a">More...</a><br /></br></td></tr>
<tr class="separator:aa68d74dc1e86e4352e00a3cab83a0e4a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a043f0ccd62e6711a18e0d81047be9a0a"><td class="memItemLeft" align="right" valign="top">arma::mat &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1ann_1_1FFN.html#a043f0ccd62e6711a18e0d81047be9a0a">Parameters</a> ()</td></tr>
<tr class="memdesc:a043f0ccd62e6711a18e0d81047be9a0a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Modify the initial point for the optimization.  <a href="#a043f0ccd62e6711a18e0d81047be9a0a">More...</a><br /></br></td></tr>
<tr class="separator:a043f0ccd62e6711a18e0d81047be9a0a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abf82c92c2116f34fb36118155da42a4e"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1ann_1_1FFN.html#abf82c92c2116f34fb36118155da42a4e">Predict</a> (arma::mat predictors, arma::mat &amp;results)</td></tr>
<tr class="memdesc:abf82c92c2116f34fb36118155da42a4e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Predict the responses to a given set of predictors.  <a href="#abf82c92c2116f34fb36118155da42a4e">More...</a><br /></br></td></tr>
<tr class="separator:abf82c92c2116f34fb36118155da42a4e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7178038c3cb8d247eadb94cd2058c432"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classmlpack_1_1ann_1_1FFN.html#a7178038c3cb8d247eadb94cd2058c432">ResetParameters</a> ()</td></tr>
<tr class="memdesc:a7178038c3cb8d247eadb94cd2058c432"><td class="mdescLeft">&#160;</td><td class="mdescRight">Reset the module infomration (weights/parameters).  <a href="#a7178038c3cb8d247eadb94cd2058c432">More...</a><br /></br></td></tr>
<tr class="separator:a7178038c3cb8d247eadb94cd2058c432"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae187181bfb4ff8601e6385fd4fc4999d"><td class="memTemplParams" colspan="2"><div class="template_expr"><div class="template_decl">template</div><div class="open_bracket">&lt;</div><div class="template_param_list"><div class="template_param"><div class="type_decl">typename</div><div class="identifier">Archive</div><div class="close_bracket">&gt;</div></div></div></div></td></tr>
<tr class="memitem:ae187181bfb4ff8601e6385fd4fc4999d"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classmlpack_1_1ann_1_1FFN.html#ae187181bfb4ff8601e6385fd4fc4999d">Serialize</a> (Archive &amp;ar, const unsigned int)</td></tr>
<tr class="memdesc:ae187181bfb4ff8601e6385fd4fc4999d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Serialize the model.  <a href="#ae187181bfb4ff8601e6385fd4fc4999d">More...</a><br /></br></td></tr>
<tr class="separator:ae187181bfb4ff8601e6385fd4fc4999d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0f09f265b04e54a39e8627a53b3cab6a"><td class="memTemplParams" colspan="2"><div class="template_expr"><div class="template_decl">template</div><div class="open_bracket">&lt;</div><div class="template_param_list"><div class="template_param"><div class="type_decl">typename</div><div class="identifier">OptimizerType</div><div class="close_bracket">&gt;</div></div></div></div></td></tr>
<tr class="memitem:a0f09f265b04e54a39e8627a53b3cab6a"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classmlpack_1_1ann_1_1FFN.html#a0f09f265b04e54a39e8627a53b3cab6a">Train</a> (arma::mat predictors, arma::mat responses, OptimizerType &amp;optimizer)</td></tr>
<tr class="memdesc:a0f09f265b04e54a39e8627a53b3cab6a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Train the feedforward network on the given input data using the given optimizer.  <a href="#a0f09f265b04e54a39e8627a53b3cab6a">More...</a><br /></br></td></tr>
<tr class="separator:a0f09f265b04e54a39e8627a53b3cab6a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a42796e9f0df7fb910f580f94462de378"><td class="memTemplParams" colspan="2"><div class="template_expr"><div class="template_decl">template</div><div class="open_bracket">&lt;</div><div class="template_param_list"><div class="template_param"><div class="type_decl">typename</div><div class="identifier">OptimizerType</div><div class="default_argument"><div class="equals">=</div><div class="identifier">mlpack::optimization::RMSProp</div></div><div class="close_bracket">&gt;</div></div></div></div></td></tr>
<tr class="memitem:a42796e9f0df7fb910f580f94462de378"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classmlpack_1_1ann_1_1FFN.html#a42796e9f0df7fb910f580f94462de378">Train</a> (arma::mat predictors, arma::mat responses)</td></tr>
<tr class="memdesc:a42796e9f0df7fb910f580f94462de378"><td class="mdescLeft">&#160;</td><td class="mdescRight">Train the feedforward network on the given input data.  <a href="#a42796e9f0df7fb910f580f94462de378">More...</a><br /></br></td></tr>
<tr class="separator:a42796e9f0df7fb910f580f94462de378"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><h3 ><br />template&lt;typename OutputLayerType = NegativeLogLikelihood&lt;&gt;, typename InitializationRuleType = RandomInitialization&gt;</br>
class mlpack::ann::FFN&lt; OutputLayerType, InitializationRuleType &gt;</h3>

<p >Implementation of a standard feed forward network. </p>
<dl class="tparams"><dt >Template Parameters</dt><dd >
  <table class="tparams">
    <tr ><td class="paramname">OutputLayerType</td><td >The output layer type used to evaluate the network. </td></tr>
    <tr ><td class="paramname">InitializationRuleType</td><td >Rule used to initialize the weight matrix. </td></tr>
  </table>
  </dd>
</dl>

<p class="definition">Definition at line <a class="el" href="ffn_8hpp_source.html#l00046">46</a> of file <a class="el" href="ffn_8hpp_source.html">ffn.hpp</a>.</p>
</div><h2 class="groupheader">Member Typedef Documentation</h2>
<a id="aa628987cefe24b56f3c1551d0588a329"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa628987cefe24b56f3c1551d0588a329">&#9670;&nbsp;</a></span>NetworkType</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr >
          <td class="memname">using <a class="el" href="classmlpack_1_1ann_1_1FFN.html#aa628987cefe24b56f3c1551d0588a329">NetworkType</a> =  <a class="el" href="classmlpack_1_1ann_1_1FFN.html">FFN</a>&lt;OutputLayerType, InitializationRuleType&gt;</td>
        </tr>
      </table>
</div><div class="memdoc">

<p >Convenience typedef for the internal model construction. </p>

<p class="definition">Definition at line <a class="el" href="ffn_8hpp_source.html#l00050">50</a> of file <a class="el" href="ffn_8hpp_source.html">ffn.hpp</a>.</p>

</div>
</div>
<h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a8a1597bba65304f53ae1cecd73b395a6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8a1597bba65304f53ae1cecd73b395a6">&#9670;&nbsp;</a></span>FFN() <span class="overload">[1/4]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr >
          <td class="memname"><a class="el" href="classmlpack_1_1ann_1_1FFN.html">FFN</a> </td>
          <td >(</td>
          <td class="paramtype">OutputLayerType&#160;</td>
          <td class="paramname"><em >outputLayer</em> = <code >OutputLayerType()</code>, </td>
        </tr>
        <tr >
          <td class="paramkey"></td>
          <td ></td>
          <td class="paramtype">InitializationRuleType&#160;</td>
          <td class="paramname"><em >initializeRule</em> = <code >InitializationRuleType()</code>&#160;</td>
        </tr>
        <tr >
          <td ></td>
          <td >)</td>
          <td ></td><td ></td>
        </tr>
      </table>
</div><div class="memdoc">

<p >Create the <a class="el" href="classmlpack_1_1ann_1_1FFN.html" title="Implementation of a standard feed forward network. ">FFN</a> object with the given predictors and responses set (this is the set that is used to train the network). </p>
<p >Optionally, specify which initialize rule and performance function should be used.</p>
<p >If you want to pass in a parameter and discard the original parameter object, be sure to use std::move to avoid unnecessary copy.</p>
<dl class="params"><dt >Parameters</dt><dd >
  <table class="params">
    <tr ><td class="paramname">outputLayer</td><td >Output layer used to evaluate the network. </td></tr>
    <tr ><td class="paramname">initializeRule</td><td >Optional instantiated InitializationRule object for initializing the network parameter. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a747c838260bf79c9b08e310660792800"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a747c838260bf79c9b08e310660792800">&#9670;&nbsp;</a></span>FFN() <span class="overload">[2/4]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr >
          <td class="memname"><a class="el" href="classmlpack_1_1ann_1_1FFN.html">FFN</a> </td>
          <td >(</td>
          <td class="paramtype">const <a class="el" href="classmlpack_1_1ann_1_1FFN.html">FFN</a>&lt; OutputLayerType, InitializationRuleType &gt; &amp;&#160;</td>
          <td class="paramname"></td><td >)</td>
          <td ></td>
        </tr>
      </table>
</div><div class="memdoc">

<p >Copy constructor. </p>

</div>
</div>
<a id="a8aa14d013d2855c06df5d78b31a126ef"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8aa14d013d2855c06df5d78b31a126ef">&#9670;&nbsp;</a></span>FFN() <span class="overload">[3/4]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr >
          <td class="memname"><a class="el" href="classmlpack_1_1ann_1_1FFN.html">FFN</a> </td>
          <td >(</td>
          <td class="paramtype"><a class="el" href="classmlpack_1_1ann_1_1FFN.html">FFN</a>&lt; OutputLayerType, InitializationRuleType &gt; &amp;&amp;&#160;</td>
          <td class="paramname"></td><td >)</td>
          <td ></td>
        </tr>
      </table>
</div><div class="memdoc">

<p >Move constructor. </p>

</div>
</div>
<a id="a11cb0ca52a8fb7e342d75582c7c5b262"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a11cb0ca52a8fb7e342d75582c7c5b262">&#9670;&nbsp;</a></span>FFN() <span class="overload">[4/4]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr >
          <td class="memname"><a class="el" href="classmlpack_1_1ann_1_1FFN.html">FFN</a> </td>
          <td >(</td>
          <td class="paramtype">arma::mat&#160;</td>
          <td class="paramname"><em >predictors</em>, </td>
        </tr>
        <tr >
          <td class="paramkey"></td>
          <td ></td>
          <td class="paramtype">arma::mat&#160;</td>
          <td class="paramname"><em >responses</em>, </td>
        </tr>
        <tr >
          <td class="paramkey"></td>
          <td ></td>
          <td class="paramtype">OutputLayerType&#160;</td>
          <td class="paramname"><em >outputLayer</em> = <code >OutputLayerType()</code>, </td>
        </tr>
        <tr >
          <td class="paramkey"></td>
          <td ></td>
          <td class="paramtype">InitializationRuleType&#160;</td>
          <td class="paramname"><em >initializeRule</em> = <code >InitializationRuleType()</code>&#160;</td>
        </tr>
        <tr >
          <td ></td>
          <td >)</td>
          <td ></td><td ></td>
        </tr>
      </table>
</div><div class="memdoc">

<p >Create the <a class="el" href="classmlpack_1_1ann_1_1FFN.html" title="Implementation of a standard feed forward network. ">FFN</a> object with the given predictors and responses set (this is the set that is used to train the network). </p>
<p >Optionally, specify which initialize rule and performance function should be used.</p>
<p >If you want to pass in a parameter and discard the original parameter object, be sure to use std::move to avoid unnecessary copy.</p>
<dl class="params"><dt >Parameters</dt><dd >
  <table class="params">
    <tr ><td class="paramname">predictors</td><td >Input training variables. </td></tr>
    <tr ><td class="paramname">responses</td><td >Outputs results from input training variables. </td></tr>
    <tr ><td class="paramname">outputLayer</td><td >Output layer used to evaluate the network. </td></tr>
    <tr ><td class="paramname">initializeRule</td><td >Optional instantiated InitializationRule object for initializing the network parameter. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a45450c5c89a5be407cbaa16523c1533d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a45450c5c89a5be407cbaa16523c1533d">&#9670;&nbsp;</a></span>~FFN()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr >
          <td class="memname">~<a class="el" href="classmlpack_1_1ann_1_1FFN.html">FFN</a> </td>
          <td >(</td>
          <td class="paramname"></td><td >)</td>
          <td ></td>
        </tr>
      </table>
</div><div class="memdoc">

<p >Destructor to release allocated memory. </p>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a8b5234495846c00f6b2c8296ca6bc718"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8b5234495846c00f6b2c8296ca6bc718">&#9670;&nbsp;</a></span>Add() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr >
  <td class="mlabels-left">
      <table class="memname">
        <tr >
          <td class="memname">void <a class="el" href="classmlpack_1_1ann_1_1Add.html">Add</a> </td>
          <td >(</td>
          <td class="paramtype">Args...&#160;</td>
          <td class="paramname"><em >args</em></td><td >)</td>
          <td ></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="ffn_8hpp_source.html#l00196">196</a> of file <a class="el" href="ffn_8hpp_source.html">ffn.hpp</a>.</p>

</div>
</div>
<a id="a463090e0ef9decba7abee503cc3afc06"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a463090e0ef9decba7abee503cc3afc06">&#9670;&nbsp;</a></span>Add() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr >
  <td class="mlabels-left">
      <table class="memname">
        <tr >
          <td class="memname">void <a class="el" href="classmlpack_1_1ann_1_1Add.html">Add</a> </td>
          <td >(</td>
          <td class="paramtype"><a class="el" href="namespacemlpack_1_1ann.html#a427481f2eba15f51860d5a225a56d8ac">LayerTypes</a>&#160;</td>
          <td class="paramname"><em >layer</em></td><td >)</td>
          <td ></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="ffn_8hpp_source.html#l00203">203</a> of file <a class="el" href="ffn_8hpp_source.html">ffn.hpp</a>.</p>

</div>
</div>
<a id="a0b003a392c76e36fe5d9c71d635c49ea"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0b003a392c76e36fe5d9c71d635c49ea">&#9670;&nbsp;</a></span>Backward()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr >
          <td class="memname">double Backward </td>
          <td >(</td>
          <td class="paramtype">arma::mat&#160;</td>
          <td class="paramname"><em >targets</em>, </td>
        </tr>
        <tr >
          <td class="paramkey"></td>
          <td ></td>
          <td class="paramtype">arma::mat &amp;&#160;</td>
          <td class="paramname"><em >gradients</em>&#160;</td>
        </tr>
        <tr >
          <td ></td>
          <td >)</td>
          <td ></td><td ></td>
        </tr>
      </table>
</div><div class="memdoc">

<p >Perform the backward pass of the data in real batch mode. </p>
<p >Forward and Backward should be used as a pair, and they are designed mainly for advanced users. User should try to use Predict and Train unless those two functions can't satisfy some special requirements.</p>
<dl class="params"><dt >Parameters</dt><dd >
  <table class="params">
    <tr ><td class="paramname">targets</td><td >The training target. </td></tr>
    <tr ><td class="paramname">gradients</td><td >Computed gradients. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt >Returns</dt><dd >Training error of the current pass. </dd></dl>

<p class="reference">Referenced by <a class="el" href="ffn_8hpp_source.html#l00211">FFN&lt; OutputLayerType, InitializationRuleType &gt;::Parameters()</a>.</p>

</div>
</div>
<a id="ac9498204c7e2b9546c00f3cf55d9879c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac9498204c7e2b9546c00f3cf55d9879c">&#9670;&nbsp;</a></span>Evaluate() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr >
          <td class="memname">double Evaluate </td>
          <td >(</td>
          <td class="paramtype">const arma::mat &amp;&#160;</td>
          <td class="paramname"><em >parameters</em>, </td>
        </tr>
        <tr >
          <td class="paramkey"></td>
          <td ></td>
          <td class="paramtype">const size_t&#160;</td>
          <td class="paramname"><em >i</em>, </td>
        </tr>
        <tr >
          <td class="paramkey"></td>
          <td ></td>
          <td class="paramtype">const bool&#160;</td>
          <td class="paramname"><em >deterministic</em> = <code >true</code>&#160;</td>
        </tr>
        <tr >
          <td ></td>
          <td >)</td>
          <td ></td><td ></td>
        </tr>
      </table>
</div><div class="memdoc">

<p >Evaluate the feedforward network with the given parameters, but using only one data point. </p>
<p >This is useful for optimizers such as SGD, which require a separable objective function.</p>
<dl class="params"><dt >Parameters</dt><dd >
  <table class="params">
    <tr ><td class="paramname">parameters</td><td >Matrix model parameters. </td></tr>
    <tr ><td class="paramname">i</td><td >Index of point to use for objective function evaluation. </td></tr>
    <tr ><td class="paramname">deterministic</td><td >Whether or not to train or test the model. Note some layer act differently in training or testing mode. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a1ca0efaedbc2e7e7542c89901cdcf2ee"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1ca0efaedbc2e7e7542c89901cdcf2ee">&#9670;&nbsp;</a></span>Evaluate() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr >
          <td class="memname">double Evaluate </td>
          <td >(</td>
          <td class="paramtype">const arma::mat &amp;&#160;</td>
          <td class="paramname"><em >parameters</em></td><td >)</td>
          <td ></td>
        </tr>
      </table>
</div><div class="memdoc">

<p >Evaluate the feedforward network with the given parameters. </p>
<p >This function is usually called by the optimizer to train the model.</p>
<dl class="params"><dt >Parameters</dt><dd >
  <table class="params">
    <tr ><td class="paramname">parameters</td><td >Matrix model parameters. </td></tr>
    <tr ><td class="paramname">deterministic</td><td >Whether or not to train or test the model. Note some layer act differently in training or testing mode. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ae072bd97493974f32b5a738fc8803c93"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae072bd97493974f32b5a738fc8803c93">&#9670;&nbsp;</a></span>Forward()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr >
          <td class="memname">void Forward </td>
          <td >(</td>
          <td class="paramtype">arma::mat&#160;</td>
          <td class="paramname"><em >inputs</em>, </td>
        </tr>
        <tr >
          <td class="paramkey"></td>
          <td ></td>
          <td class="paramtype">arma::mat &amp;&#160;</td>
          <td class="paramname"><em >results</em>&#160;</td>
        </tr>
        <tr >
          <td ></td>
          <td >)</td>
          <td ></td><td ></td>
        </tr>
      </table>
</div><div class="memdoc">

<p >Perform the forward pass of the data in real batch mode. </p>
<p >Forward and Backward should be used as a pair, and they are designed mainly for advanced users. User should try to use Predict and Train unless those two functions can't satisfy some special requirements.</p>
<dl class="params"><dt >Parameters</dt><dd >
  <table class="params">
    <tr ><td class="paramname">inputs</td><td >The input data. </td></tr>
    <tr ><td class="paramname">results</td><td >The predicted results. </td></tr>
  </table>
  </dd>
</dl>

<p class="reference">Referenced by <a class="el" href="ffn_8hpp_source.html#l00211">FFN&lt; OutputLayerType, InitializationRuleType &gt;::Parameters()</a>.</p>

</div>
</div>
<a id="a71b4d1c08d05fb5219e600e4e6b07f18"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a71b4d1c08d05fb5219e600e4e6b07f18">&#9670;&nbsp;</a></span>Gradient()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr >
          <td class="memname">void Gradient </td>
          <td >(</td>
          <td class="paramtype">const arma::mat &amp;&#160;</td>
          <td class="paramname"><em >parameters</em>, </td>
        </tr>
        <tr >
          <td class="paramkey"></td>
          <td ></td>
          <td class="paramtype">const size_t&#160;</td>
          <td class="paramname"><em >i</em>, </td>
        </tr>
        <tr >
          <td class="paramkey"></td>
          <td ></td>
          <td class="paramtype">arma::mat &amp;&#160;</td>
          <td class="paramname"><em >gradient</em>&#160;</td>
        </tr>
        <tr >
          <td ></td>
          <td >)</td>
          <td ></td><td ></td>
        </tr>
      </table>
</div><div class="memdoc">

<p >Evaluate the gradient of the feedforward network with the given parameters, and with respect to only one point in the dataset. </p>
<p >This is useful for optimizers such as SGD, which require a separable objective function.</p>
<dl class="params"><dt >Parameters</dt><dd >
  <table class="params">
    <tr ><td class="paramname">parameters</td><td >Matrix of the model parameters to be optimized. </td></tr>
    <tr ><td class="paramname">i</td><td >Index of points to use for objective function gradient evaluation. </td></tr>
    <tr ><td class="paramname">gradient</td><td >Matrix to output gradient into. </td></tr>
  </table>
  </dd>
</dl>

<p class="reference">Referenced by <a class="el" href="ffn_8hpp_source.html#l00211">FFN&lt; OutputLayerType, InitializationRuleType &gt;::Parameters()</a>.</p>

</div>
</div>
<a id="a1fa76af34a6e3ea927b307f0c318ee4b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1fa76af34a6e3ea927b307f0c318ee4b">&#9670;&nbsp;</a></span>NumFunctions()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr >
  <td class="mlabels-left">
      <table class="memname">
        <tr >
          <td class="memname">size_t NumFunctions </td>
          <td >(</td>
          <td class="paramname"></td><td >)</td>
          <td > const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p >Return the number of separable functions (the number of predictor points). </p>

<p class="definition">Definition at line <a class="el" href="ffn_8hpp_source.html#l00206">206</a> of file <a class="el" href="ffn_8hpp_source.html">ffn.hpp</a>.</p>

</div>
</div>
<a id="ad3218e6a988d7203fd6a0ced3e457057"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad3218e6a988d7203fd6a0ced3e457057">&#9670;&nbsp;</a></span>operator=()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr >
          <td class="memname"><a class="el" href="classmlpack_1_1ann_1_1FFN.html">FFN</a>&amp; operator= </td>
          <td >(</td>
          <td class="paramtype"><a class="el" href="classmlpack_1_1ann_1_1FFN.html">FFN</a>&lt; OutputLayerType, InitializationRuleType &gt;&#160;</td>
          <td class="paramname"></td><td >)</td>
          <td ></td>
        </tr>
      </table>
</div><div class="memdoc">

<p >Copy/move assignment operator. </p>

</div>
</div>
<a id="aa68d74dc1e86e4352e00a3cab83a0e4a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa68d74dc1e86e4352e00a3cab83a0e4a">&#9670;&nbsp;</a></span>Parameters() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr >
  <td class="mlabels-left">
      <table class="memname">
        <tr >
          <td class="memname">const arma::mat&amp; Parameters </td>
          <td >(</td>
          <td class="paramname"></td><td >)</td>
          <td > const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p >Return the initial point for the optimization. </p>

<p class="definition">Definition at line <a class="el" href="ffn_8hpp_source.html#l00209">209</a> of file <a class="el" href="ffn_8hpp_source.html">ffn.hpp</a>.</p>

</div>
</div>
<a id="a043f0ccd62e6711a18e0d81047be9a0a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a043f0ccd62e6711a18e0d81047be9a0a">&#9670;&nbsp;</a></span>Parameters() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr >
  <td class="mlabels-left">
      <table class="memname">
        <tr >
          <td class="memname">arma::mat&amp; Parameters </td>
          <td >(</td>
          <td class="paramname"></td><td >)</td>
          <td ></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p >Modify the initial point for the optimization. </p>

<p class="definition">Definition at line <a class="el" href="ffn_8hpp_source.html#l00211">211</a> of file <a class="el" href="ffn_8hpp_source.html">ffn.hpp</a>.</p>

<p class="reference">References <a class="el" href="classmlpack_1_1ann_1_1FFN.html#a0b003a392c76e36fe5d9c71d635c49ea">FFN&lt; OutputLayerType, InitializationRuleType &gt;::Backward()</a>, <a class="el" href="classmlpack_1_1ann_1_1FFN.html#ae072bd97493974f32b5a738fc8803c93">FFN&lt; OutputLayerType, InitializationRuleType &gt;::Forward()</a>, <a class="el" href="classmlpack_1_1ann_1_1FFN.html#a71b4d1c08d05fb5219e600e4e6b07f18">FFN&lt; OutputLayerType, InitializationRuleType &gt;::Gradient()</a>, <a class="el" href="classmlpack_1_1ann_1_1FFN.html#a7178038c3cb8d247eadb94cd2058c432">FFN&lt; OutputLayerType, InitializationRuleType &gt;::ResetParameters()</a>, and <a class="el" href="classmlpack_1_1ann_1_1FFN.html#ae187181bfb4ff8601e6385fd4fc4999d">FFN&lt; OutputLayerType, InitializationRuleType &gt;::Serialize()</a>.</p>

</div>
</div>
<a id="abf82c92c2116f34fb36118155da42a4e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abf82c92c2116f34fb36118155da42a4e">&#9670;&nbsp;</a></span>Predict()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr >
          <td class="memname">void Predict </td>
          <td >(</td>
          <td class="paramtype">arma::mat&#160;</td>
          <td class="paramname"><em >predictors</em>, </td>
        </tr>
        <tr >
          <td class="paramkey"></td>
          <td ></td>
          <td class="paramtype">arma::mat &amp;&#160;</td>
          <td class="paramname"><em >results</em>&#160;</td>
        </tr>
        <tr >
          <td ></td>
          <td >)</td>
          <td ></td><td ></td>
        </tr>
      </table>
</div><div class="memdoc">

<p >Predict the responses to a given set of predictors. </p>
<p >The responses will reflect the output of the given output layer as returned by the output layer function.</p>
<p >If you want to pass in a parameter and discard the original parameter object, be sure to use std::move to avoid unnecessary copy.</p>
<dl class="params"><dt >Parameters</dt><dd >
  <table class="params">
    <tr ><td class="paramname">predictors</td><td >Input predictors. </td></tr>
    <tr ><td class="paramname">results</td><td >Matrix to put output predictions of responses into. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a7178038c3cb8d247eadb94cd2058c432"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7178038c3cb8d247eadb94cd2058c432">&#9670;&nbsp;</a></span>ResetParameters()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr >
          <td class="memname">void ResetParameters </td>
          <td >(</td>
          <td class="paramname"></td><td >)</td>
          <td ></td>
        </tr>
      </table>
</div><div class="memdoc">

<p >Reset the module infomration (weights/parameters). </p>

<p class="reference">Referenced by <a class="el" href="ffn_8hpp_source.html#l00211">FFN&lt; OutputLayerType, InitializationRuleType &gt;::Parameters()</a>.</p>

</div>
</div>
<a id="ae187181bfb4ff8601e6385fd4fc4999d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae187181bfb4ff8601e6385fd4fc4999d">&#9670;&nbsp;</a></span>Serialize()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr >
          <td class="memname">void Serialize </td>
          <td >(</td>
          <td class="paramtype">Archive &amp;&#160;</td>
          <td class="paramname"><em >ar</em>, </td>
        </tr>
        <tr >
          <td class="paramkey"></td>
          <td ></td>
          <td class="paramtype">const unsigned&#160;</td>
          <td class="paramname"><em >int</em>&#160;</td>
        </tr>
        <tr >
          <td ></td>
          <td >)</td>
          <td ></td><td ></td>
        </tr>
      </table>
</div><div class="memdoc">

<p >Serialize the model. </p>

<p class="reference">Referenced by <a class="el" href="ffn_8hpp_source.html#l00211">FFN&lt; OutputLayerType, InitializationRuleType &gt;::Parameters()</a>.</p>

</div>
</div>
<a id="a0f09f265b04e54a39e8627a53b3cab6a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0f09f265b04e54a39e8627a53b3cab6a">&#9670;&nbsp;</a></span>Train() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr >
          <td class="memname">void Train </td>
          <td >(</td>
          <td class="paramtype">arma::mat&#160;</td>
          <td class="paramname"><em >predictors</em>, </td>
        </tr>
        <tr >
          <td class="paramkey"></td>
          <td ></td>
          <td class="paramtype">arma::mat&#160;</td>
          <td class="paramname"><em >responses</em>, </td>
        </tr>
        <tr >
          <td class="paramkey"></td>
          <td ></td>
          <td class="paramtype">OptimizerType &amp;&#160;</td>
          <td class="paramname"><em >optimizer</em>&#160;</td>
        </tr>
        <tr >
          <td ></td>
          <td >)</td>
          <td ></td><td ></td>
        </tr>
      </table>
</div><div class="memdoc">

<p >Train the feedforward network on the given input data using the given optimizer. </p>
<p >This will use the existing model parameters as a starting point for the optimization. If this is not what you want, then you should access the parameters vector directly with <a class="el" href="classmlpack_1_1ann_1_1FFN.html#a043f0ccd62e6711a18e0d81047be9a0a" title="Modify the initial point for the optimization. ">Parameters()</a> and modify it as desired.</p>
<p >If you want to pass in a parameter and discard the original parameter object, be sure to use std::move to avoid unnecessary copy.</p>
<dl class="tparams"><dt >Template Parameters</dt><dd >
  <table class="tparams">
    <tr ><td class="paramname">OptimizerType</td><td >Type of optimizer to use to train the model. </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt >Parameters</dt><dd >
  <table class="params">
    <tr ><td class="paramname">predictors</td><td >Input training variables. </td></tr>
    <tr ><td class="paramname">responses</td><td >Outputs results from input training variables. </td></tr>
    <tr ><td class="paramname">optimizer</td><td >Instantiated optimizer used to train the model. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a42796e9f0df7fb910f580f94462de378"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a42796e9f0df7fb910f580f94462de378">&#9670;&nbsp;</a></span>Train() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr >
          <td class="memname">void Train </td>
          <td >(</td>
          <td class="paramtype">arma::mat&#160;</td>
          <td class="paramname"><em >predictors</em>, </td>
        </tr>
        <tr >
          <td class="paramkey"></td>
          <td ></td>
          <td class="paramtype">arma::mat&#160;</td>
          <td class="paramname"><em >responses</em>&#160;</td>
        </tr>
        <tr >
          <td ></td>
          <td >)</td>
          <td ></td><td ></td>
        </tr>
      </table>
</div><div class="memdoc">

<p >Train the feedforward network on the given input data. </p>
<p >By default, the RMSProp optimization algorithm is used, but others can be specified (such as <a class="el" href="classmlpack_1_1optimization_1_1SGD.html" title="Stochastic Gradient Descent is a technique for minimizing a function which can be expressed as a sum ...">mlpack::optimization::SGD</a>).</p>
<p >This will use the existing model parameters as a starting point for the optimization. If this is not what you want, then you should access the parameters vector directly with <a class="el" href="classmlpack_1_1ann_1_1FFN.html#a043f0ccd62e6711a18e0d81047be9a0a" title="Modify the initial point for the optimization. ">Parameters()</a> and modify it as desired.</p>
<p >If you want to pass in a parameter and discard the original parameter object, be sure to use std::move to avoid unnecessary copy.</p>
<dl class="tparams"><dt >Template Parameters</dt><dd >
  <table class="tparams">
    <tr ><td class="paramname">OptimizerType</td><td >Type of optimizer to use to train the model. </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt >Parameters</dt><dd >
  <table class="params">
    <tr ><td class="paramname">predictors</td><td >Input training variables. </td></tr>
    <tr ><td class="paramname">responses</td><td >Outputs results from input training variables. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<hr ></hr>The documentation for this class was generated from the following file:<ul >
<li >src/mlpack/methods/ann/<a class="el" href="ffn_8hpp_source.html">ffn.hpp</a></li>
</ul>
</div>

<hr class="footer"></hr><address class="footer"><small >
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"></img>
</a> 1.8.13
</small></address>
</div>
</body>
<script type="text/javascript">
var x = document.querySelectorAll("img.formulaDsp");
var i;
for (i = 0; i < x.length; i++)
{
  x[i].width = x[i].offsetWidth / 4;
}
</script>
</html>